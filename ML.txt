                                              MACHINE LEARNING WORKSHEET 
                               
                               
                               
In Q1 to Q7, only one option is correct, Choose the correct option:

1. The value of correlation coefficient will always be:
    A) between 0 and 1  B) greater than -1
    C) between -1 and 1 D) between 0 and -1

    Answer: C) between -1 and 1
    
2. Which of the following cannot be used for dimensionality reduction?
    A) Lasso Regularisation          B) PCA
    C) Recursive feature elimination D) Ridge Regularisation
    
    Answer: D) Ridge Regularisation
    
3. Which of the following is not a kernel in Support Vector Machines?
    A) linear      B) Radial Basis Function
    C) hyperplane  D) polynomial
    
    Answer: C) hyperplane
    
4. Amongst the following, which one is least suitable for a dataset having non-linear decision boundaries?
    A) Logistic Regression      B) Naïve Bayes Classifier
    C) Decision Tree Classifier D) Support Vector Classifier
    
    Answer: B) Naïve Bayes Classifier
    
5. In a Linear Regression problem, ‘X’ is independent variable and ‘Y’ is dependent variable, where ‘X’ represents
    weight in pounds. If you convert the unit of ‘X’ to kilograms, then new coefficient of ‘X’ will be?
    (1 kilogram = 2.205 pounds)
    A) 2.205 × old coefficient of ‘X’    B) same as old coefficient of ‘X’
    C) old coefficient of ‘X’ ÷ 2.205    D) Cannot be determined
    
    Answer: A) 2.205 × old coefficient of ‘X’
    
6. As we increase the number of estimators in ADABOOST Classifier, what happens to the accuracy of the model?
    A) remains same B) increases
    C) decreases    D) none of the above
    
    Answer: A) remains same
    
7. Which of the following is not an advantage of using random forest instead of decision trees?
    A) Random Forests reduce overfitting
    B) Random Forests explains more variance in data then decision trees
    C) Random Forests are easy to interpret
    D) Random Forests provide a reliable feature importance estimate
    
    Answer: B) Random Forests explains more variance in data then decision trees
    
 
 
In Q8 to Q10, more than one options are correct, Choose all the correct options:

8. Which of the following are correct about Principal Components?
    A) Principal Components are calculated using supervised learning techniques
    B) Principal Components are calculated using unsupervised learning techniques
    C) Principal Components are linear combinations of Linear Variables.
    D) All of the above
    
    Answer: A) Principal Components are calculated using supervised learning techniques
            B) Principal Components are calculated using unsupervised learning techniques
            
9. Which of the following are applications of clustering?
    A) Identifying developed, developing and under-developed countries on the basis of factors like GDP, poverty
       index, employment rate, population and living index
    B) Identifying loan defaulters in a bank on the basis of previous years’ data of loan accounts.
    C) Identifying spam or ham emails
    D) Identifying different segments of disease based on BMI, blood pressure, cholesterol, blood sugar levels.
    
    Answer: A) Identifying developed, developing and under-developed countries on the basis of factors like GDP, poverty
               index, employment rate, population and living index
            B) Identifying loan defaulters in a bank on the basis of previous years’ data of loan accounts.
            D) Identifying different segments of disease based on BMI, blood pressure, cholesterol, blood sugar levels.
    
10. Which of the following is(are) hyper parameters of a decision tree?
    A) max_depth    B) max_features
    C) n_estimators D) min_samples_leaf
    
    Answer:  A) max_depth    
             B) max_features
             D) min_samples_leaf
    
    
    
Q10 to Q15 are subjective answer type questions, Answer them briefly.

11. What are outliers? Explain the Inter Quartile Range(IQR) method for outlier detection.

    Answer: outlier is a data point that is distant from other similar points. They may be due to variability in 
    the measurement or may indicate experimental errors. Machine learning algorithms are sensitive. Data outliers 
    can spoil and mislead the training process resulting in less accurate models
    
    Outliers can be of two kinds: 1) univariate
                                  2) multivariate.
                                  
                                  
    Inter Quartile Range(IQR) : IQR = Q3 – Q1. 
    These five numbers which give you the information you need to find outliers.              
                    1) minimum 
                    2) first quartile Q1
                    3) median 
                    4) third quartile Q3
                    5) maximum 
                    
             The interquartile range can be used to detect outliers. This is done using these steps:
                     1) Calculate the interquartile range for the data.
                     2) Multiply the interquartile range by 1.5
                     3) Add 1.5 x (IQR) to the third quartile.
                        note (Any number greater than this is a suspected outlier)
                     4) Subtract 1.5 x (IQR) from the first quartile. 
                        note (Any number less than this is a suspected outlier )


12. What is the primary difference between bagging and boosting algorithms?
   
    Answer: Bagging and Boosting are two types of Ensemble Learning.
    
                                     BAGGING                                                BOOSTING
                                       
                                   Random forest                                        Gradient boosting
                                       
                   Simplest way of combining predictions that                 A way of combining predictions that
                          belong to the same type                                belong to the different types
                          
                   Bagging tries to solve over-fitting problem                    Boosting tries to reduce bias
                   
                         Each model is built independently                  New models are influenced by performance of 
                                                                                       previously built models
                                                    
                 If the classifier is unstable (high variance)             If the classifier is stable and simple (high bias).                                                 then apply bagging                                     the apply boosting
     


13. What is adjusted R2 in logistic regression. How is it calculated?

    Answer: The adjusted R-squared is a modified version of R-squared that has been adjusted for the number of 
            predictors in the model. Adjusted R-squared increases only when independent variable is significant
            and affects dependent variable. Adjusted r-squared can be negative when r-squared is close to zero.
            Adjusted r-squared value always be less than or equal to r-squared value.
            
            Adjusted R-Squared can be calculated mathematically in terms of sum of squares. 
            The only difference between R-square and Adjusted R-square equation is degree of freedom.
            
            Adjusted R-squared value can be calculated based on value of r-squared, number of independent
            variables (predictors), total sample size.
            
            Formula :adjusted r2 = 1-(1-r2)(N-1)/N-p-1
             here : r2 = r square
                     p = number of predictors
                     N = total sample size



14. What is the difference between standardisation and normalisation?

    Answer: Normalization is a scaling technique in which values are shifted and rescaled so that
            they end up ranging between 0 and 1. It is also known as Min-Max scaling
            
            Standardization is scaling technique where the values are centered around the 
            mean with a unit standard deviation.
            
                             normalisation                                           standardisation
               
                   Minimum and maximum value of features              Mean and standard deviation is used for scaling
                          are used for scaling

                  Scales values between [0, 1] or [-1, 1]                    It is not bounded to a certain range
                  
                       It is really affected by outliers                     It is much less affected by outliers
                       
                  It is a often called as Scaling Normalization          It is a often called as Z-Score Normalization
                  
                  Scikit-Learn provides a transformer called        Scikit-Learn provides a transformer called StandardScaler
                        MinMaxScaler for Normalization.                             for standardization.



15. What is cross-validation? Describe one advantage and one disadvantage of using cross-validation.

    Answer: Cross-validation is a technique that is used to find how the results of statistical 
            analysis generalize to an independent data set. Cross-validation is largely used in 
            where the target is prediction. It is also necessary to estimate the accuracy of the
            performance of a predictive model.
            
            Advantage: Reduces Overfitting
            
            Disadvantage: Increases Training Time