                                               DEEP LEARNING – WORKSHEET 3
                                               
                                               
Q1 to Q8 are MCQs with only one correct answer. Choose the correct option.

1. Which of the following is true about model capacity 
    (where model capacity means the ability of neural network to approximate complex functions)?
    A) As dropout ratio increases, model capacity increases
    B) As number of hidden layers increase, model capacity increases
    C) As learning rate increases, model capacity increases
    D) None of the above
    
    Answer: B) As number of hidden layers increase, model capacity increases
    
    
2. Batch Normalization is helpful because?
    A) It is a very efficient backpropagation technique
    B) It returns back the normalized mean and standard deviation of weights
    C) It normalizes (changes) all the input before sending it to the next layer
    D) None of the above
    
    Answer: C) It normalizes (changes) all the input before sending it to the next layer
    
    
3. What if we use a learning rate that’s too large?
    A) Network will not converge 
    B) Network will converge
    C) either A or B 
    D) None of the above
    
    Answer: B) Network will converge
    
    
4. What are the factors to select the depth of neural network?
    i) Type of neural network (e.g. MLP, CNN etc.)
    ii) Input data
    iii) Computation power, i.e. Hardware capabilities and software capabilities
    iv) Learning Rate
    v) The output function to map
        A) 1, 2, 4, 5 
        B) 2, 3, 4, 5
        C) 1, 3, 4, 5 
        D) All of these
        
        Answer: D) All of these
        
        
5. Suppose you have inputs as x, y, and z with values -2, 5, and -4 respectively. You have a neuron ‘q’ and neuron ‘f’
    with functions:
        q = x + y
        f = q * z
    Graphical representation of the functions is as follows:
    What is the gradient of F with respect to x, y, and z? (use chain rule of derivatives to find the solution)
    A) ( 3, -4, -4) 
    B) (-3,  4,  4)
    C) (-4, -4,  3) 
    D) ( 4,  4,  3)
    
    
    Answer: C) (-4, -4,  3)
    
    
6. Which of the following statement is the best description of early stopping?
    A) Train the network until a local minimum in the error function is reached
    B) Simulate the network on a test dataset after every epoch of training. Stop training when the generalization
       error starts to increase
    C) Add a momentum term to the weight update in the Generalized Delta Rule, so that training converges more quickly
    D) None of the above

    Answer: B) Simulate the network on a test dataset after every epoch of training. Stop training when the generalization
               error starts to increase
    
    
7. Which gradient descent technique is more advantageous when the data is too big to handle in RAM simultaneously?
    A) Mini Batch Gradient Descent 
    B) Stochastic Gradient Descent
    C) Full Batch Gradient Descent 
    D) either A or B
    
    Answer: B) Stochastic Gradient Descent
    
    
8. Consider the scenario. The problem you are trying to solve has a small amount of data. Fortunately, you have a
   pre-trained neural network that was trained on a similar problem. Which of the following methodologies would
   you choose to make use of this pre-trained network?
    A) Freeze all the layers except the last, re-train the last layer
    B) Assess on every layer how the model performs and only select a few of them
    C) Fine tune the last couple of layers only
    D) Re-train the model for the new dataset
    
    Answer: A) Freeze all the layers except the last, re-train the last layer
    
    
Q9 and Q10 are MCQs with one or more correct answers. Choose all the correct options.

9. Which of the following neural network training challenge can be solved using batch normalization?
    A) Overfitting 
    B) Training is too slow
    C) Restrict activations to become too high or low
    D) None of these
    
    Answer: A) Overfitting 
            C) Restrict activations to become too high or low
    
    
10. For a binary classification problem, which of the following activations may be used in output layer?
    A) ReLU 
    B) sigmoid
    C) softmax 
    D) Leaky ReLU
    
    Answer: B) sigmoid
            C) softmax
    
    
Q11 to Q15 are subjective answer type question. Answer them briefly.

11. What will happen if we do not use activation function in artificial neural networks?
    
    Answer:  Activation function decides, whether a neuron should be activated or not by calculating weighted sum and 
             further adding bias with it. The purpose of the activation function is to introduce non-linearity into the 
             output of a neuron.
             We know, neural network has neurons that work in correspondence of weight, bias and their respective activation 
             function. In a neural network, we would update the weights and biases of the neurons on the basis of the error
             at the output. This process is known as back-propagation. Activation functions make the back-propagation possible 
             since the gradients are supplied along with the error to update the weights and biases.
             A neural network without an activation function is essentially just a linear regression model. The activation 
             function does the non-linear transformation to the input making it capable to learn and perform more complex tasks.
                    Input for layer  2 is output from layer 1
                                z(2) = W(2)a(1) + b(2)  
                                a(2) = z(2)

                                // Putting value of z(1) here

                                z(2) = (W(2) * [W(1)X + b(1)]) + b(2) 
                                z(2) = [W(2) * W(1)] * X + [W(2)*b(1) + b(2)]
                                Let, 
                                    [W(2) * W(1)] = W
                                    [W(2)*b(1) + b(2)] = b

                                Final output : z(2) = W*X + b
                                Which is again a linear function
            This observation results again in a linear function even after applying a hidden layer, hence we can conclude that,
            doesn’t matter how many hidden layer we attach in neural net, all layers will behave same way because the composition 
            of two linear function is a linear function itself. Neuron can not learn with just a linear function attached to it.
            A non-linear activation function will let it learn as per the difference w.r.t error.
            Hence we need activation function.




12. How does forward propagation and backpropagation work in deep learning?

    Answer: Forward propagation refers to the calculation and storage of intermediate variables 
            (including outputs) for a neural network in order from the input layer to the output layer. We now work step-by-step 
            through the mechanics of a neural network with one hidden layer. 
            This may seem tedious but in the eternal words of funk virtuoso James Brown, you must “pay the cost to be the boss”.

            For the sake of simplicity, let us assume that the input example is  x∈Rd  and that our hidden layer does not include 
            a bias term. Here the intermediate variable is:
                                                                z=W(1)x
 
            where  W(1)∈Rh×d  is the weight parameter of the hidden layer. After running the intermediate variable  z∈Rh  through 
            the activation function  ϕ  we obtain our hidden activation vector of length  h 

                                                                h=ϕ(z)
 
            The hidden variable  h  is also an intermediate variable. Assuming that the parameters of the output layer only possess 
            a weight of  W(2)∈Rq×h , we can obtain an output layer variable with a vector of length  q 

                                                                o=W(2)h
 
            Assuming that the loss function is  l  and the example label is  y , we can then calculate the loss term for a single 
            data example,

                                                                L=l(o,y)
 
            According to the definition of  L2  regularization, given the hyperparameter  λ , the regularization term is

                                                        s=λ2(∥W(1)∥2F+∥W(2)∥2F)
 
            where the Frobenius norm of the matrix is simply the  L2  norm applied after flattening the matrix into a vector. 
            Finally, the model’s regularized loss on a given data example is

                                                                J=L+s.
 
            We refer to  J  as the objective function in the following discussion.
            
            Backpropagation refers to the method of calculating the gradient of neural network parameters. In short, 
            the method traverses the network in reverse order, from the output to the input layer, according to the chain 
            rule from calculus. 
            The algorithm stores any intermediate variables (partial derivatives) required while calculating the gradient
            with respect to some parameters. 
            Assume that we have functions  Y=f(X)  and  Z=g(Y) , in which the input and the output  X,Y,Z  are tensors of
            arbitrary shapes. By using the chain rule, 
            we can compute the derivative of  Z  with respect to  X  via

                                                        ∂Z∂X = prod(∂Z∂Y,∂Y∂X).




13. Explain briefly the following variant of Gradient Descent: Stochastic, Batch, and Mini-batch?

    Answer: Gradient descent is a first-order iterative optimization algorithm for finding the minimum of a function.
            The goal of the gradient descent is to minimise a given function which, in our case, is the loss function 
            of the neural network.

            Batch Gradient Descent
            
            In Batch Gradient Descent, all the training data is taken into consideration to take a single step. 
            We take the average of the gradients of all the training examples and then use that mean gradient to update our 
            parameters. So that’s just one step of gradient descent in one epoch. Batch Gradient Descent is great for convex 
            or relatively smooth error manifolds. In this case, we move somewhat directly towards an optimum solution.
           
           Stochastic Gradient Descent
           
           In Batch Gradient Descent we were considering all the examples for every step of Gradient Descent. But what if 
           our dataset is very huge. Deep learning models crave for data. The more the data the more chances of a model to be good. 
           Suppose our dataset has 5 million examples, then just to take one step the model will have to calculate the gradients 
           of all the 5 million examples. This does not seem an efficient way. 
           To tackle this problem we have Stochastic Gradient Descent. In Stochastic Gradient Descent (SGD), we consider just 
           one example at a time to take a single step. We do the following steps in one epoch for SGD:
           1. Take an example
           2. Feed it to Neural Network
           3. Calculate it’s gradient
           4. Use the gradient we calculated in step 3 to update the weights
           5. Repeat steps 1–4 for all the examples in training dataset
          
           Mini Batch Gradient Descent
           
           We have seen the Batch Gradient Descent and Stochastic Gradient Descent.
           Batch Gradient Descent can be used for smoother curves. 
           SGD can be used when the dataset is large. 
           Batch Gradient Descent converges directly to minima. 
           SGD converges faster for larger datasets. 
           But, since in SGD we use only one example at a time, we cannot implement the vectorized implementation on it. 
           This can slow down the computations. 
           To tackle this problem, a mixture of Batch Gradient Descent and SGD is used.
           Neither we use all the dataset all at once nor we use the single example at a time. 
           We use a batch of a fixed number of training examples which is less than the actual dataset and call it a mini-batch.
           Doing this helps us achieve the advantages of both the former variants we saw. 
            1. Pick a mini-batch
            2. Feed it to Neural Network
            3. Calculate the mean gradient of the mini-batch
            4. Use the mean gradient we calculated in step 3 to update the weights
            5. Repeat steps 1–4 for the mini-batches we create
            
            

14. What are the main benefits of Mini-batch Gradient Descent?

    Answer: Mini-batch Gradient Descent is a mixture of both stochastic and batch gradient descent. 
            The training set is divided into multiple groups called batches. Each batch has a number of training samples in it.
            At a time a single batch is passed through the network which computes the loss of every sample in the batch and uses
            their average to update the parameters of the neural network. 
            For example, say the training set has 100 training examples which is divided into 5 batches with each batch containing 
            20 training examples. 
            This means that the equation will be iterated over 5 times (number of batches).

            stochastic and batch gradient descent are used due to which Mini Batch Gradient Descent is most commonly used in practice.
                    1. Easily fits in the memory
                    2. It is computationally efficient
                    3. Benefit from vectorization
                    4. If stuck in local minimums, some noisy steps can lead the way out of them
                    5. Average of the training samples produces stable error gradients and convergence
                    
                    
                    
15. What is transfer learning?

    Answer: Transfer learning is the reuse of a pre-trained model on a new problem. It's currently very popular in 
            deep learning because it can train deep neural networks with comparatively little data. This is very 
            useful in the data science field since most real-world problems typically do not have millions of labeled
            data points to train such complex models. 
            Transfer learning, used in machine learning, is the reuse of a pre-trained model on a new problem. 
            In transfer learning, a machine exploits the knowledge gained from a previous task to improve generalization 
            about another.
            For example, in training a classifier to predict whether an image contains food, you could use the knowledge 
            it gained during training to recognize it as drinks.

