                                                DEEP LEARNING – WORKSHEET 5
                                                
Q1 to Q8 are MCQs with only one correct answer. Choose the correct option.

1. Which of the following are advantages of batch normalization?
    A) Reduces internal covariant shift.
    B) Regularizes the model and reduces the need for dropout, photometric distortions, local response
       normalization and other regularization techniques.
    C) allows use of saturating nonlinearities and higher learning rates.
    D) All of the above
    
    Answer: A) Reduces internal covariant shift
    
    
2. Which of the following is not a problem with sigmoid activation function?
    A) Sigmoids do not saturate and hence have faster convergence
    B) Sigmoids have slow convergence.
    C) Sigmoids saturate and kill gradients.
    D) Sigmoids are not zero centered; gradient updates go too far in different directions, making optimization more difficult.
    
    Answer:  C) Sigmoids saturate and kill gradients
    
    
3. Which of the following is not an activation function?
    A) Swish 
    B) Maxout
    C) SoftPlus 
    D) None of the above
    
    Answer: D) None of the above
    
    
4. The tanh activation usually works better than sigmoid activation function for hidden units because the mean of
   its output is closer to zero, and so it centers the data better for the next layer. True/False?
    A) True 
    B) False
    
    Answer: A) True 
    
    
5. In which of the weights initialisation techniques, does the variance remains same with each passing layer?
    A) Bias initialisation 
    B) Xavier Initialisation
    C) He Normal Initialisation 
    D) None of these
    
    Answer: B) Xavier Initialisation
    
    
6. Which of the following is main weakness of AdaGrad?
    A) learning rate shrinks and becomes infinitesimally small
    B) learning rate doesn’t shrink beyond a point
    C) change in learning rate is not adaptive
    D) AdaGrad adapts updates to each individual parameter
    
    Answer: A) learning rate shrinks and becomes infinitesimally small
    
    
7. In order to achieve right convergence faster, which of the following criteria is most suitable?
    A) momentum and learning rate both must be high
    B) momentum must be high and learning rate must be low
    C) momentum and learning rate both must be low
    D) momentum must be low and learning rate must be high
    
    Answer: A) momentum and learning rate both must be high
    
    
8. When is an error landscape is said to be poor(ill) conditioned?
    A) when it has many local minima
    B) when it has many local maxima
    C) when it has many saddle points and flat areas
    D) None of these
    
    Answer: D) None of these
    
    
Q9 and Q10 are MCQs with one or more correct answers. Choose all the correct options.

9. Which of the following Gradient Descent algorithms are adaptive?
    A) ADAM 
    B) SGD
    C) NADAM 
    D) RMS Prop
    
    Answer: A) ADAM 
            C) NADAM 
            D) RMS Prop
            
    
10. When should an optimization function (gradient descent algorithm) stop training:
    A) when it reaches local minimum 
    B) when it reaches saddle point
    C) when it reaches global minimum
    D) when it reaches a local minima which is similar to global minima 
       (i.e. which has very less error distance with global minima)
       
    Answer: A) when it reaches local minimum 
            B) when it reaches saddle point
            C) when it reaches global minimum
    
    
    
Q11 to Q15 are subjective answer type question. Answer them briefly.

11. What are convex, non-convex optimization?
    Answer: A convex optimization problem is a problem where all of the constraints are convex functions, and the objective 
            is a convex function if minimizing, or a concave function if maximizing.  
            Linear functions are convex, so linear programming problems are convex problems.  
           
           A non-convex optimization problem is any problem where the objective or any of the constraints are non-convex.
           Such a problem may have multiple feasible regions and multiple locally optimal points within each region.  
           It can take time exponential in the number of variables and constraints to determine that a non-convex problem 
           is infeasible, that the objective function is unbounded, or that an optimal solution is the "global optimum" across 
           all feasible regions.



12. What do you mean by saddle point? Answer briefly.
    Answer: Saddle point
            Saddle point is a point in the domain of a function that is a stationary point but not a local extremum. 
            The name derives from the fact that the prototypical example in two dimensions is a surface that curves up
            in one direction, and curves down in a different direction, resembling a saddle or a mountain pass. 
            In terms of contour lines, a saddle point in two dimensions gives rise to a contour that appears to intersect itself.




13. What is the main difference between classical momentum and Nesterov momentum? Explain briefly.
    Answer: The classical momentum velocity vector is defined by Bengio as:

                                             vt=μt−1vt−1−εt−1∇f(θt−1)

            Sutskever gives the same definition but without any t subscript on the velocity vector or the momentum coefficient.

            We can write out the full update for classical momentum as:

                                            θt+1=θt+μtvt−εt∇f(θt)
                                            with velocity:

                                            vt+1=μtvt−εt∇f(θt)

            The Nesterov Accelerated Gradient method consists of a gradient descent step, followed by something that looks a lot 
            like a momentum term, but isn’t exactly the same as that found in classical momentum. I’ll call it a “momentum stage” here.
            It’s important to note that the parameters being minimized by NAG are given the symbol y by Sutskever, not θ. 
            You’ll see that θ is the symbol for the parameters after they’ve been updated by the gradient descent stage,
            but before the momentum stage.

                                        Here’s the gradient descent stage:
                                        θt=yt−εt∇f(yt)



14. What is Pre initialisation of weights? Explain briefly.
    Answer: The aim of weight initialization is to prevent layer activation outputs from exploding or vanishing during 
            the course of a forward pass through a deep neural network. 
            If either occurs, loss gradients will either be too large or too small to flow backwards beneficially,
            and the network will take longer to converge, if it is even able to do so at all.
            Matrix multiplication is the essential math operation of a neural network. In deep neural nets with several layers, 
            one forward pass simply entails performing consecutive matrix multiplications at each layer, between that layer’s 
            inputs and weight matrix. 
            The product of this multiplication at one layer becomes the inputs of the subsequent layer, and so on and so forth.
            It’s standard practice when training neural networks to ensure that our inputs’ values are scaled such that they fall 
            inside such a normal distribution with a mean of 0 and a standard deviation of 1.



15. What is internal covariance shift in Neural Networks ?
    Answer: Internal covariate shift
            An internal covariate shift occurs when there is a change in the input distribution to our network. When the input 
            distribution changes, hidden layers try to learn to adapt to the new distribution. This slows down the training process. 
            If a process slows down, it takes a long time to converge to a global minimum. 
            This problem occurs when the statistical distribution of the input to the networks is drastically different from the 
            input that it has seen before. Batch normalization and other normalization techniques can solve this problem. 

